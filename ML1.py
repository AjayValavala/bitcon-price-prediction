# -*- coding: utf-8 -*-
"""ML1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19VJg04QeLbN2DzheBY0C1dBsy66hd4pK
"""



import pandas as pd

# Load the dataset
file_path = "/content/drive/MyDrive/ML_LAB/Bitcoin Historical Data6.csv"
btc_data = pd.read_csv(file_path)

# Display the first 5 rows
print(btc_data.head())

# Display column names
print(btc_data.columns)

print(btc_data.head())

print(btc_data.head())

# Convert 'Date' column to datetime format (if available)
'''if 'Date' in btc_data.columns:
    btc_data['Date'] = pd.to_datetime(btc_data['Date'])
    btc_data.set_index('Date', inplace=True)'''

numeric_columns = ['Price', 'Open', 'High', 'Low']  # Adjust based on actual column names

# Remove commas and convert to numeric
for col in numeric_columns:
    btc_data[col] = btc_data[col].astype(str).str.replace(',', '') # Remove commas
    btc_data[col] = pd.to_numeric(btc_data[col], errors='coerce') # Convert to float
    '''btc_data[col] = btc_data[col].apply(pd.eval).astype(float)'''

''' btc_data['Price'] = btc_data['Price'].astype(str)  # Ensure it's a string
btc_data['Price'] = btc_data['Price'].str.replace('K', '*1e3').str.replace('%', '')  # Replace 'K' and '%'
btc_data['Price'] = btc_data['Price'].apply(pd.eval).astype(float)  # Evaluate expressions and convert to float'''


# Drop rows with missing values
btc_data.dropna(inplace=True)

# Display the cleaned data
print(btc_data.head())

# Select the Close price as feature
btc_data['Future_Close'] = btc_data['Price'].shift(-1)

# Drop last row (since it has no future price)
btc_data.dropna(inplace=True)

# Features (X) and target variable (y)
X = btc_data[['Price', 'Open', 'High', 'Low']]

y = btc_data['Future_Close']

# Split into training (80%) and testing (20%)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training data size:",X_train.shape)
print("Testing data size:",X_test.shape)

from sklearn.metrics import mean_absolute_error

# Train the Linear Regression model
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict on test data
y_pred = model.predict(X_test)

# Evaluate model performance
mae = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error:",mae)

import pickle
filename = 'ML1'
pickle.dump(model,open(filename,'wb'))

load_regmodel = pickle.load(open(filename,'rb'))

import pickle
'''
# Load the scaler (assuming it was saved to a file called 'scaler.pkl')
scaler = pickle.load(open('scaler.pkl', 'rb'))'''

# Directly predict with the input (if no scaling was applied during training)
new_input = [[71347, 69358, 71442, 69110]]

# Make the prediction with the loaded model
prediction = load_regmodel.predict(new_input)

print("Prediction for the input [71347, 69358, 71442, 69110] is:", prediction)
